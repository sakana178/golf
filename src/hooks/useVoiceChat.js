/**
 * useVoiceChat - VAD é©±åŠ¨çš„è¿žç»­å¯¹è¯ Hook
 * 
 * åŠŸèƒ½ï¼š
 *   1. éº¦å…‹é£Žå¸¸å¼€ï¼ŒVAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ´»åŠ¨
 *   2. é™éŸ³è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤ 700msï¼‰è‡ªåŠ¨è§¦å‘è¯†åˆ«
 *   3. TTS æ’­æ”¾æ—¶æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯è‡ªåŠ¨æ‰“æ–­ï¼ˆbarge-inï¼‰
 *   4. å®Œå…¨åŸºäºŽ REST APIï¼Œä¸ä½¿ç”¨ WebSocket
 * 
 * VAD å®žçŽ°ï¼šåŸºäºŽèƒ½é‡é˜ˆå€¼çš„ç®€å• VAD
 *   - è®¡ç®—æ¯å¸§éŸ³é¢‘çš„ RMS èƒ½é‡
 *   - è¶…è¿‡é˜ˆå€¼è®¤ä¸ºæœ‰å£°éŸ³ï¼Œä½ŽäºŽé˜ˆå€¼è®¤ä¸ºé™éŸ³
 *   - è¿žç»­é™éŸ³è¶…è¿‡æŒ‡å®šæ—¶é—´è®¤ä¸ºä¸€å¥è¯ç»“æŸ
 * 
 * ä½¿ç”¨æ–¹å¼ï¼š
 *   const { isActive, isSpeaking, isProcessing, start, stop } = useVoiceChat({
 *     onResult: (text) => { ... },
 *     onError: (error) => { ... },
 *     silenceThreshold: 700,  // é™éŸ³é˜ˆå€¼ï¼ˆmsï¼‰
 *     energyThreshold: 0.01,  // èƒ½é‡é˜ˆå€¼ï¼ˆ0-1ï¼‰
 *   });
 */

import { useState, useRef, useCallback, useEffect } from 'react';
import { getUiLanguage } from '../utils/language';

// ==================== é…ç½®å¸¸é‡ ====================

// ç™¾åº¦è¯­éŸ³è¯†åˆ« API é…ç½®
const BAIDU_APP_ID = 121810527;
const BAIDU_API_KEY = 'IkBpJulK2jDfZybH9XlBEFDz';
const BAIDU_SECRET_KEY = 'ksVOfq21zIwRgaHfy2gRCpKJrPgYte7I';

// ç™¾åº¦è¯­éŸ³åˆæˆ API é…ç½®
const TTS_API_KEY = 'j0xBgZAd65ydvM9zO36SqNmL';
const TTS_SECRET_KEY = 'Q0KztLX8lcIUu6JpzWVEx8MwgnbgW6EL';

// VAD é»˜è®¤é…ç½®
const DEFAULT_CONFIG = {
    silenceThreshold: 700,      // é™éŸ³å¤šä¹…è®¤ä¸ºä¸€å¥è¯ç»“æŸï¼ˆmsï¼‰
    energyThreshold: 0.015,     // RMS èƒ½é‡é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œä½ŽäºŽæ­¤å€¼è®¤ä¸ºé™éŸ³
    minSpeechDuration: 300,     // æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼ˆmsï¼‰ï¼Œé˜²æ­¢å™ªå£°è¯¯è§¦å‘
    maxSpeechDuration: 30000,   // æœ€é•¿å•æ¬¡å½•éŸ³æ—¶é•¿ï¼ˆmsï¼‰ï¼Œé˜²æ­¢æ— é™å½•éŸ³
    frameSize: 2048,            // æ¯å¸§é‡‡æ ·æ•°
    targetSampleRate: 16000,    // ç›®æ ‡é‡‡æ ·çŽ‡
    smoothingFrames: 3,         // èƒ½é‡å¹³æ»‘å¸§æ•°ï¼Œå‡å°‘æŠ–åŠ¨
};

// ==================== Token ç¼“å­˜ ====================

let asrCachedToken = null;
let asrTokenExpireTime = 0;
let ttsCachedToken = null;
let ttsTokenExpireTime = 0;

// æ¸…é™¤ token ç¼“å­˜ï¼ˆç”¨äºŽè°ƒè¯•ï¼‰
export const clearTokenCache = () => {
    asrCachedToken = null;
    asrTokenExpireTime = 0;
    ttsCachedToken = null;
    ttsTokenExpireTime = 0;
    console.log('ðŸ—‘ï¸ Token ç¼“å­˜å·²æ¸…é™¤');
};

// èŽ·å–ç™¾åº¦ ASR access_token
const getAsrAccessToken = async () => {
    if (asrCachedToken && Date.now() < asrTokenExpireTime) {
        console.log('ðŸ”‘ ä½¿ç”¨ç¼“å­˜çš„ ASR token');
        return asrCachedToken;
    }
    const tokenUrl = `/baidu-token?grant_type=client_credentials&client_id=${BAIDU_API_KEY}&client_secret=${BAIDU_SECRET_KEY}`;
    console.log('ðŸ”‘ è¯·æ±‚æ–°çš„ ASR token...', { BAIDU_API_KEY, BAIDU_SECRET_KEY: BAIDU_SECRET_KEY.substring(0, 5) + '...' });
    try {
        const response = await fetch(tokenUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
        });
        const data = await response.json();
        console.log('ðŸ”‘ Token å“åº”:', data);
        if (data.access_token) {
            asrCachedToken = data.access_token;
            asrTokenExpireTime = Date.now() + (29 * 24 * 60 * 60 * 1000);
            console.log('âœ… ASR token èŽ·å–æˆåŠŸ:', asrCachedToken.substring(0, 20) + '...');
            return asrCachedToken;
        }
        throw new Error(data.error_description || 'èŽ·å– ASR token å¤±è´¥');
    } catch (error) {
        console.error('âŒ èŽ·å– ASR token å¤±è´¥:', error);
        throw error;
    }
};

// èŽ·å–ç™¾åº¦ TTS access_token
const getTtsAccessToken = async () => {
    if (ttsCachedToken && Date.now() < ttsTokenExpireTime) {
        return ttsCachedToken;
    }
    const tokenUrl = `/baidu-token?grant_type=client_credentials&client_id=${TTS_API_KEY}&client_secret=${TTS_SECRET_KEY}`;
    try {
        const response = await fetch(tokenUrl, { method: 'POST' });
        const data = await response.json();
        if (data.access_token) {
            ttsCachedToken = data.access_token;
            ttsTokenExpireTime = Date.now() + (29 * 24 * 60 * 60 * 1000);
            return ttsCachedToken;
        }
        throw new Error(data.error_description || 'èŽ·å– TTS token å¤±è´¥');
    } catch (error) {
        console.error('âŒ èŽ·å– TTS token å¤±è´¥:', error);
        throw error;
    }
};

// ==================== éŸ³é¢‘å¤„ç†å·¥å…·å‡½æ•° ====================

// Float32Array è½¬ 16-bit PCM
const floatTo16BitPCM = (float32Array) => {
    const pcm16 = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
        const s = Math.max(-1, Math.min(1, float32Array[i]));
        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return pcm16;
};

// é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·çŽ‡
const resampleAudio = (inputFloat32, inputSampleRate, targetSampleRate) => {
    if (inputSampleRate === targetSampleRate) return inputFloat32;
    const ratio = inputSampleRate / targetSampleRate;
    const newLength = Math.round(inputFloat32.length / ratio);
    const resampled = new Float32Array(newLength);
    for (let i = 0; i < newLength; i++) {
        const srcIndex = i * ratio;
        const index = Math.floor(srcIndex);
        const fraction = srcIndex - index;
        if (index + 1 < inputFloat32.length) {
            resampled[i] = inputFloat32[index] * (1 - fraction) + inputFloat32[index + 1] * fraction;
        } else {
            resampled[i] = inputFloat32[index];
        }
    }
    return resampled;
};

// ArrayBuffer è½¬ base64
const arrayBufferToBase64 = (buffer) => {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
        binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
};

// è®¡ç®—éŸ³é¢‘å¸§çš„ RMS èƒ½é‡
const calculateRMS = (samples) => {
    if (!samples || samples.length === 0) return 0;
    let sum = 0;
    for (let i = 0; i < samples.length; i++) {
        sum += samples[i] * samples[i];
    }
    return Math.sqrt(sum / samples.length);
};

const getRealtimeDevPid = () => (getUiLanguage('zh') === 'en' ? 1737 : 1537);

// ==================== è¯­éŸ³è¯†åˆ« API (WebSocket å®žæ—¶è¯†åˆ«) ====================

const recognizeSpeech = async (pcmData) => {
    const accessToken = await getAsrAccessToken();
    const audioLen = pcmData.buffer.byteLength;

    console.log('ðŸŽ¯ WebSocket è¯†åˆ«ï¼ŒéŸ³é¢‘å­—èŠ‚æ•°:', audioLen);

    return new Promise((resolve, reject) => {
        // åˆ›å»º WebSocket è¿žæŽ¥
        const wsUrl = `wss://vop.baidu.com/realtime_asr?sn=${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        const ws = new WebSocket(wsUrl);
        ws.binaryType = 'arraybuffer';

        let finalResult = '';
        let partialResults = [];
        let hasError = false;

        // è¿žæŽ¥è¶…æ—¶å¤„ç†
        const timeout = setTimeout(() => {
            if (ws.readyState !== WebSocket.CLOSED) {
                ws.close();
                reject(new Error('WebSocket è¿žæŽ¥è¶…æ—¶'));
            }
        }, 10000);

        ws.onopen = () => {
            console.log('ðŸ”Œ WebSocket å·²è¿žæŽ¥');
            clearTimeout(timeout);

            // å‘é€å¼€å§‹å¸§ï¼ˆæ³¨æ„ï¼šä½¿ç”¨ sample è€Œä¸æ˜¯ rateï¼‰
            const startFrame = JSON.stringify({
                type: 'START',
                data: {
                    appid: BAIDU_APP_ID,
                    appkey: BAIDU_API_KEY,
                    dev_pid: getRealtimeDevPid(),
                    cuid: 'golf_vad_' + Math.random().toString(36).substr(2, 9),
                    format: 'pcm',
                    sample: 16000,  // æ³¨æ„ï¼šè¿™é‡Œæ˜¯ sample ä¸æ˜¯ rate
                    channel: 1,
                }
            });
            ws.send(startFrame);
            console.log('ðŸ“¤ å‘é€ START å¸§:', startFrame);

            // å‘é€éŸ³é¢‘æ•°æ®å¸§ï¼ˆåˆ†ç‰‡å‘é€ï¼Œæ¯ç‰‡æœ€å¤§ 8KBï¼‰
            const chunkSize = 8192;
            const buffer = pcmData.buffer;
            let offset = 0;

            const sendChunk = () => {
                if (offset >= buffer.byteLength) {
                    // å‘é€ç»“æŸå¸§
                    const finishFrame = JSON.stringify({ type: 'FINISH' });
                    ws.send(finishFrame);
                    console.log('ðŸ“¤ å‘é€ FINISH å¸§');
                    return;
                }

                const chunk = buffer.slice(offset, offset + chunkSize);
                ws.send(chunk);
                offset += chunkSize;

                // ç»§ç»­å‘é€ä¸‹ä¸€ç‰‡ï¼ˆé—´éš” 40msï¼Œæ¨¡æ‹Ÿå®žæ—¶æµï¼‰
                setTimeout(sendChunk, 40);
            };

            sendChunk();
        };

        ws.onmessage = (event) => {
            try {
                const message = JSON.parse(event.data);
                console.log('ðŸ“¥ æ”¶åˆ°æ¶ˆæ¯:', message.type, message);

                if (message.type === 'MID_TEXT') {
                    // ä¸­é—´ç»“æžœ
                    partialResults.push(message.result);
                    console.log('ðŸ“ ä¸­é—´ç»“æžœ:', message.result);
                } else if (message.type === 'FIN_TEXT') {
                    // æœ€ç»ˆç»“æžœ
                    finalResult = message.result;
                    console.log('âœ… æœ€ç»ˆç»“æžœ:', finalResult);
                } else if (message.type === 'SERVER_ERR') {
                    // æœåŠ¡å™¨é”™è¯¯
                    hasError = true;
                    const errorMsg = message.message || 'æœåŠ¡å™¨é”™è¯¯';
                    console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', errorMsg);
                    reject(new Error(errorMsg));
                }
            } catch (err) {
                console.error('âŒ è§£æžæ¶ˆæ¯å¤±è´¥:', err);
            }
        };

        ws.onerror = (error) => {
            console.error('âŒ WebSocket é”™è¯¯:', error);
            clearTimeout(timeout);
            if (!hasError) {
                reject(new Error('WebSocket è¿žæŽ¥å¤±è´¥'));
            }
        };

        ws.onclose = (event) => {
            console.log('ðŸ”Œ WebSocket å·²å…³é—­ï¼Œcode:', event.code);
            clearTimeout(timeout);

            if (!hasError) {
                // ä¼˜å…ˆä½¿ç”¨æœ€ç»ˆç»“æžœï¼Œå¦åˆ™ä½¿ç”¨æœ€åŽä¸€ä¸ªä¸­é—´ç»“æžœ
                const result = finalResult || (partialResults.length > 0 ? partialResults[partialResults.length - 1] : '');

                if (result && result.trim().length > 0) {
                    resolve(result);
                } else {
                    reject(new Error('æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³'));
                }
            }
        };
    });
};

// ==================== è¯­éŸ³åˆæˆ API ====================

const synthesizeSpeech = async (text, options = {}) => {
    if (!text || text.length === 0) throw new Error('æ–‡æœ¬ä¸ºç©º');
    if (text.length > 2048) text = text.substring(0, 2048);

    const accessToken = await getTtsAccessToken();
    const params = new URLSearchParams({
        tex: text,
        tok: accessToken,
        cuid: 'golf_vad_' + Math.random().toString(36).substr(2, 9),
        ctp: '1',
        lan: options.lan || 'zh',
        spd: String(options.spd || '5'),
        pit: String(options.pit || '5'),
        vol: String(options.vol || '5'),
        per: String(options.per || '0'),
        aue: String(options.aue || '3')
    });

    const response = await fetch('/baidu-tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
        body: params.toString()
    });

    if (!response.ok) {
        throw new Error(`TTS è¯·æ±‚å¤±è´¥: ${response.status}`);
    }

    const contentType = response.headers.get('content-type');
    if (contentType && contentType.includes('application/json')) {
        const errorData = await response.json();
        throw new Error(`TTS é”™è¯¯: ${errorData.err_msg || errorData.err_no}`);
    }

    return await response.blob();
};

// ==================== ä¸» Hook ====================

export const useVoiceChat = (options = {}) => {
    const config = { ...DEFAULT_CONFIG, ...options };

    // çŠ¶æ€
    const [isActive, setIsActive] = useState(false);           // æ˜¯å¦å·²å¯åŠ¨ï¼ˆéº¦å…‹é£Žå¸¸å¼€ï¼‰
    const [isSpeaking, setIsSpeaking] = useState(false);       // ç”¨æˆ·æ˜¯å¦æ­£åœ¨è¯´è¯ï¼ˆVAD æ£€æµ‹ï¼‰
    const [isProcessing, setIsProcessing] = useState(false);   // æ˜¯å¦æ­£åœ¨å¤„ç†ï¼ˆè¯†åˆ«ä¸­ï¼‰
    const [isTtsPlaying, setIsTtsPlaying] = useState(false);   // TTS æ˜¯å¦æ­£åœ¨æ’­æ”¾
    const [error, setError] = useState(null);                  // é”™è¯¯ä¿¡æ¯

    // Refs
    const streamRef = useRef(null);
    const audioContextRef = useRef(null);
    const processorRef = useRef(null);
    const sourceRef = useRef(null);
    const audioChunksRef = useRef([]);
    const sampleRateRef = useRef(0);

    // VAD çŠ¶æ€
    const vadStateRef = useRef({
        isSpeaking: false,
        silenceStart: null,
        speechStart: null,
        energyHistory: [],
    });

    // TTS ç›¸å…³
    const ttsAudioRef = useRef(null);
    const ttsUrlRef = useRef(null);

    // å›žè°ƒ refs
    const onResultRef = useRef(options.onResult);
    const onErrorRef = useRef(options.onError);
    const onSpeechStartRef = useRef(options.onSpeechStart);
    const onSpeechEndRef = useRef(options.onSpeechEnd);
    const onTtsInterruptRef = useRef(options.onTtsInterrupt);

    // æ›´æ–°å›žè°ƒ refs
    useEffect(() => {
        onResultRef.current = options.onResult;
        onErrorRef.current = options.onError;
        onSpeechStartRef.current = options.onSpeechStart;
        onSpeechEndRef.current = options.onSpeechEnd;
        onTtsInterruptRef.current = options.onTtsInterrupt;
    }, [options.onResult, options.onError, options.onSpeechStart, options.onSpeechEnd, options.onTtsInterrupt]);

    // åœæ­¢ TTS æ’­æ”¾
    const stopTts = useCallback(() => {
        if (ttsAudioRef.current) {
            ttsAudioRef.current.pause();
            ttsAudioRef.current.currentTime = 0;
            ttsAudioRef.current = null;
        }
        if (ttsUrlRef.current) {
            URL.revokeObjectURL(ttsUrlRef.current);
            ttsUrlRef.current = null;
        }
        setIsTtsPlaying(false);
    }, []);

    // å¤„ç†ä¸€å¥è¯ç»“æŸï¼šå‘é€è¯†åˆ«è¯·æ±‚
    const processUtterance = useCallback(async () => {
        const chunks = audioChunksRef.current;
        const sampleRate = sampleRateRef.current;

        if (chunks.length === 0 || !sampleRate) {
            console.log('âš ï¸ æ— æœ‰æ•ˆéŸ³é¢‘æ•°æ®');
            return;
        }

        // åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
        const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
        const merged = new Float32Array(totalLength);
        let offset = 0;
        for (const chunk of chunks) {
            merged.set(chunk, offset);
            offset += chunk.length;
        }

        // æ£€æŸ¥æ—¶é•¿
        const duration = totalLength / sampleRate * 1000;
        if (duration < config.minSpeechDuration) {
            console.log(`âš ï¸ éŸ³é¢‘å¤ªçŸ­ (${duration.toFixed(0)}ms < ${config.minSpeechDuration}ms)ï¼Œå¿½ç•¥`);
            return;
        }

        console.log(`ðŸŽ¤ å¤„ç†è¯­éŸ³ç‰‡æ®µ: ${(duration / 1000).toFixed(2)}ç§’`);
        setIsProcessing(true);

        try {
            // é‡é‡‡æ ·åˆ° 16kHz
            const resampled = resampleAudio(merged, sampleRate, config.targetSampleRate);
            // è½¬æ¢ä¸º 16-bit PCM
            const pcmData = floatTo16BitPCM(resampled);
            // è¯†åˆ«
            const text = await recognizeSpeech(pcmData);

            if (text && onResultRef.current) {
                onResultRef.current(text);
            }
        } catch (err) {
            console.error('âŒ è¯†åˆ«å¤±è´¥:', err);
            setError(err.message);
            if (onErrorRef.current) {
                onErrorRef.current(err);
            }
        } finally {
            setIsProcessing(false);
        }
    }, [config.minSpeechDuration, config.targetSampleRate]);

    // VAD å¤„ç†ï¼šæ¯å¸§è°ƒç”¨
    const handleAudioFrame = useCallback((samples) => {
        const vad = vadStateRef.current;
        const now = Date.now();

        // è®¡ç®— RMS èƒ½é‡ï¼ˆå¸¦å¹³æ»‘ï¼‰
        const rms = calculateRMS(samples);
        vad.energyHistory.push(rms);
        if (vad.energyHistory.length > config.smoothingFrames) {
            vad.energyHistory.shift();
        }
        const avgEnergy = vad.energyHistory.reduce((a, b) => a + b, 0) / vad.energyHistory.length;

        const isVoice = avgEnergy > config.energyThreshold;

        // çŠ¶æ€æœºï¼šæ£€æµ‹è¯­éŸ³å¼€å§‹å’Œç»“æŸ
        if (isVoice) {
            // æ£€æµ‹åˆ°å£°éŸ³
            if (!vad.isSpeaking) {
                // è¯­éŸ³å¼€å§‹
                console.log('ðŸŽ™ï¸ VAD: æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹');
                vad.isSpeaking = true;
                vad.speechStart = now;
                vad.silenceStart = null;
                audioChunksRef.current = []; // æ¸…ç©ºä¹‹å‰çš„æ•°æ®
                setIsSpeaking(true);

                // Barge-in: å¦‚æžœ TTS æ­£åœ¨æ’­æ”¾ï¼Œæ‰“æ–­å®ƒ
                if (ttsAudioRef.current) {
                    console.log('âš¡ Barge-in: æ‰“æ–­ TTS æ’­æ”¾');
                    stopTts();
                    if (onTtsInterruptRef.current) {
                        onTtsInterruptRef.current();
                    }
                }

                if (onSpeechStartRef.current) {
                    onSpeechStartRef.current();
                }
            }
            vad.silenceStart = null;

            // æ”¶é›†éŸ³é¢‘æ•°æ®
            audioChunksRef.current.push(new Float32Array(samples));

            // æ£€æŸ¥æœ€å¤§æ—¶é•¿
            if (vad.speechStart && (now - vad.speechStart) > config.maxSpeechDuration) {
                console.log('âš ï¸ è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œå¼ºåˆ¶ç»“æŸ');
                vad.isSpeaking = false;
                setIsSpeaking(false);
                processUtterance();
                vad.speechStart = null;
                if (onSpeechEndRef.current) {
                    onSpeechEndRef.current();
                }
            }
        } else {
            // é™éŸ³
            if (vad.isSpeaking) {
                // æ­£åœ¨è¯´è¯ä¸­é‡åˆ°é™éŸ³
                if (!vad.silenceStart) {
                    vad.silenceStart = now;
                }

                // ç»§ç»­æ”¶é›†ï¼ˆå¯èƒ½æ˜¯åœé¡¿ï¼‰
                audioChunksRef.current.push(new Float32Array(samples));

                // æ£€æŸ¥é™éŸ³æ—¶é•¿
                const silenceDuration = now - vad.silenceStart;
                if (silenceDuration >= config.silenceThreshold) {
                    // ä¸€å¥è¯ç»“æŸ
                    console.log(`ðŸ›‘ VAD: é™éŸ³ ${silenceDuration}msï¼Œä¸€å¥è¯ç»“æŸ`);
                    vad.isSpeaking = false;
                    vad.speechStart = null;
                    vad.silenceStart = null;
                    setIsSpeaking(false);

                    if (onSpeechEndRef.current) {
                        onSpeechEndRef.current();
                    }

                    // è§¦å‘è¯†åˆ«
                    processUtterance();
                }
            }
        }
    }, [config.energyThreshold, config.silenceThreshold, config.smoothingFrames, config.maxSpeechDuration, processUtterance, stopTts]);

    // å¯åŠ¨éº¦å…‹é£Žå’Œ VAD
    const start = useCallback(async () => {
        if (isActive) {
            console.log('âš ï¸ å·²ç»åœ¨è¿è¡Œä¸­');
            return;
        }

        console.log('ðŸš€ å¯åŠ¨ VAD è¯­éŸ³å¯¹è¯...');
        setError(null);

        try {
            // è¯·æ±‚éº¦å…‹é£Žæƒé™
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                }
            });

            streamRef.current = stream;

            // åˆ›å»º AudioContext
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            audioContextRef.current = audioContext;
            sampleRateRef.current = audioContext.sampleRate;

            console.log(`ðŸŽ¤ éº¦å…‹é£Žå·²å¯åŠ¨ï¼Œé‡‡æ ·çŽ‡: ${audioContext.sampleRate}Hz`);

            // åˆ›å»ºå¤„ç†èŠ‚ç‚¹
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(config.frameSize, 1, 1);

            sourceRef.current = source;
            processorRef.current = processor;

            // åˆå§‹åŒ– VAD çŠ¶æ€
            vadStateRef.current = {
                isSpeaking: false,
                silenceStart: null,
                speechStart: null,
                energyHistory: [],
            };
            audioChunksRef.current = [];

            // å¤„ç†éŸ³é¢‘å¸§
            processor.onaudioprocess = (e) => {
                const inputData = e.inputBuffer.getChannelData(0);
                handleAudioFrame(inputData);
            };

            // è¿žæŽ¥èŠ‚ç‚¹
            source.connect(processor);
            processor.connect(audioContext.destination);

            setIsActive(true);
            console.log('âœ… VAD è¯­éŸ³å¯¹è¯å·²å¯åŠ¨ï¼Œç­‰å¾…ç”¨æˆ·è¯´è¯...');

        } catch (err) {
            console.error('âŒ å¯åŠ¨å¤±è´¥:', err);
            let errorMessage = 'å¯åŠ¨å¤±è´¥';
            if (err.name === 'NotAllowedError') {
                errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»';
            } else if (err.name === 'NotFoundError') {
                errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£Žè®¾å¤‡';
            } else if (err.name === 'NotReadableError') {
                errorMessage = 'éº¦å…‹é£Žè¢«å ç”¨';
            }
            setError(errorMessage);
            if (onErrorRef.current) {
                onErrorRef.current(new Error(errorMessage));
            }
        }
    }, [isActive, config.frameSize, handleAudioFrame]);

    // åœæ­¢
    const stop = useCallback(() => {
        console.log('ðŸ›‘ åœæ­¢ VAD è¯­éŸ³å¯¹è¯');

        // æ–­å¼€éŸ³é¢‘èŠ‚ç‚¹
        if (processorRef.current) {
            processorRef.current.disconnect();
            processorRef.current.onaudioprocess = null;
            processorRef.current = null;
        }
        if (sourceRef.current) {
            sourceRef.current.disconnect();
            sourceRef.current = null;
        }

        // å…³é—­ AudioContext
        if (audioContextRef.current) {
            audioContextRef.current.close().catch(() => { });
            audioContextRef.current = null;
        }

        // åœæ­¢éº¦å…‹é£Ž
        if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
        }

        // åœæ­¢ TTS
        stopTts();

        // é‡ç½®çŠ¶æ€
        vadStateRef.current = {
            isSpeaking: false,
            silenceStart: null,
            speechStart: null,
            energyHistory: [],
        };
        audioChunksRef.current = [];
        sampleRateRef.current = 0;

        setIsActive(false);
        setIsSpeaking(false);
        setIsProcessing(false);
        setError(null);

        console.log('âœ… å·²åœæ­¢');
    }, [stopTts]);

    // æ’­æ”¾ TTS
    const speak = useCallback(async (text, options = {}) => {
        if (!text || text.trim().length === 0) {
            console.warn('âš ï¸ TTS æ–‡æœ¬ä¸ºç©º');
            return;
        }

        // åœæ­¢ä¹‹å‰çš„æ’­æ”¾
        stopTts();

        try {
            console.log('ðŸ”Š åˆæˆè¯­éŸ³:', text.substring(0, 50) + (text.length > 50 ? '...' : ''));
            setIsTtsPlaying(true);

            const audioBlob = await synthesizeSpeech(text, options);
            const audioUrl = URL.createObjectURL(audioBlob);
            ttsUrlRef.current = audioUrl;

            const audio = new Audio(audioUrl);
            ttsAudioRef.current = audio;

            audio.onended = () => {
                console.log('âœ… TTS æ’­æ”¾å®Œæˆ');
                setIsTtsPlaying(false);
                ttsAudioRef.current = null;
                if (ttsUrlRef.current) {
                    URL.revokeObjectURL(ttsUrlRef.current);
                    ttsUrlRef.current = null;
                }
            };

            audio.onerror = (err) => {
                console.error('âŒ TTS æ’­æ”¾å¤±è´¥:', err);
                setIsTtsPlaying(false);
                ttsAudioRef.current = null;
            };

            await audio.play();
            console.log('ðŸŽµ TTS æ’­æ”¾ä¸­...');

        } catch (err) {
            console.error('âŒ TTS åˆæˆå¤±è´¥:', err);
            setIsTtsPlaying(false);
            if (onErrorRef.current) {
                onErrorRef.current(err);
            }
        }
    }, [stopTts]);

    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
    useEffect(() => {
        return () => {
            if (isActive) {
                stop();
            }
        };
    }, [isActive, stop]);

    return {
        // çŠ¶æ€
        isActive,           // æ˜¯å¦å·²å¯åŠ¨ï¼ˆéº¦å…‹é£Žå¸¸å¼€ï¼‰
        isSpeaking,         // ç”¨æˆ·æ˜¯å¦æ­£åœ¨è¯´è¯
        isProcessing,       // æ˜¯å¦æ­£åœ¨è¯†åˆ«
        isTtsPlaying,       // TTS æ˜¯å¦æ­£åœ¨æ’­æ”¾
        error,              // é”™è¯¯ä¿¡æ¯

        // æ–¹æ³•
        start,              // å¯åŠ¨éº¦å…‹é£Žå’Œ VAD
        stop,               // åœæ­¢ä¸€åˆ‡
        speak,              // æ’­æ”¾ TTSï¼ˆä¼šè¢« barge-in æ‰“æ–­ï¼‰
        stopTts,            // æ‰‹åŠ¨åœæ­¢ TTS
    };
};

// ==================== å…¼å®¹æ—§æŽ¥å£çš„ Wrapper ====================

/**
 * useVoiceInput - å…¼å®¹æ—§æŽ¥å£çš„ wrapper
 * ä¿æŒåŽŸæœ‰çš„ startListening / stopListening æŽ¥å£ï¼Œä½†å†…éƒ¨ä½¿ç”¨ VAD
 */
export const useVoiceInput = () => {
    const callbackRef = useRef(null);

    const {
        isActive,
        isSpeaking,
        isProcessing,
        error,
        start,
        stop,
    } = useVoiceChat({
        onResult: (text) => {
            if (callbackRef.current) {
                callbackRef.current(text);
            }
        },
        onError: (err) => {
            console.error('è¯­éŸ³è¾“å…¥é”™è¯¯:', err);
        }
    });

    const startListening = useCallback(async (onResult) => {
        callbackRef.current = onResult;
        await start();
    }, [start]);

    const stopListening = useCallback(() => {
        callbackRef.current = null;
        stop();
    }, [stop]);

    return {
        isListening: isActive || isSpeaking || isProcessing,
        hasSupport: typeof navigator !== 'undefined' && !!navigator.mediaDevices,
        startListening,
        stopListening,
        error,
    };
};

export default useVoiceChat;
